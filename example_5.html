<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.min.css">
	<title>Example 4</title>
</head>
<body>
	<a href="./index.html"> << back</a>
	<div class="center-align">
		<h1>Example 4</h1>
		<p>getUserMedia() - getAudioTracks() - AudioContext()</p>
		<input type="button" value="Start1" onclick="start()" id="startBtn">
		<input type="button" value="Start2" onclick="start()" id="startBtn2">
		<input type="button" value="Stop" id="stopBtn">
		<video controls src=""></video>
		<a id="download">Download</a>
		<audio controls autoplay></audio>
	</div>

	<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
	<script>
		let arrayAudio = [];
		var startBtn = document.getElementById('startBtn');
		var startBtn2 = document.getElementById('startBtn2');
		let stop_Btn = document.getElementById('stopBtn');
		let videoElement = document.querySelector('video');
		let audioElement = document.querySelector('audio');
		const downloadLink = document.getElementById('download');

		function start() {
			navigator.mediaDevices.getUserMedia({ audio: true, video: false })
			.then(gotStreamMethod5)
			.catch(logError);
			// startBtn.disabled = true;
		}

		function gotStreamMethod5(stream) {
			var audioCtx = new (window.AudioContext || window.webkitAudioContext)();
			var source;
			// var button = startBtn;
			// var pre = document.querySelector('pre');
			// var myScript = document.querySelector('script');
			
			// pre.innerHTML = myScript.innerHTML;
			
			// Stereo
			var channels = 2;
			// Create an empty two second stereo buffer at the
			// sample rate of the AudioContext
			var frameCount = audioCtx.sampleRate * 2.0;
			
			// var source = audioCtx.createMediaStreamSource(stream);

			var myArrayBuffer = audioCtx.createBuffer(2, frameCount, audioCtx.sampleRate);

			// console.log('gotStreamMethod5');

			startBtn.addEventListener('click', function(){
				console.log('button.onclick = function() {');
				// Fill the buffer with white noise;
				//just random values between -1.0 and 1.0
				for (var channel = 0; channel < channels; channel++) {
						console.log('channel '+channel);
					// This gives us the actual ArrayBuffer that contains the data
					var nowBuffering = myArrayBuffer.getChannelData(channel);
					for (var i = 0; i < frameCount; i++) {
						console.log('channel '+channel);					
						// Math.random() is in [0; 1.0]
						// audio needs to be in [-1.0; 1.0]
						nowBuffering[i] = Math.random() * 2 - 1;
					}
				}
			
				// Get an AudioBufferSourceNode.
				// This is the AudioNode to use when we want to play an AudioBuffer
				source = audioCtx.createBufferSource();
				// set the buffer in the AudioBufferSourceNode
				source.buffer = myArrayBuffer;
				// connect the AudioBufferSourceNode to the
				// destination so we can hear the sound
				source.connect(audioCtx.destination);
				// start the source playing
				// source.start();
			});

			startBtn2.addEventListener('click', function(){
				source.start();
			});
			
			stop_Btn.addEventListener('click', function(){
				console.log('click Stop');
			});
		}

		function logError(error) {
			alert(error);
			console.log(error);
		}
	</script>
</body>
</html>
