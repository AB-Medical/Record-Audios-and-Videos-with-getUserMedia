<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
	 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.min.css">
	<title>Example 3</title>
</head>
<body>
	<a href="./index.html"> << back</a>
	<div class="center-align">
		<h1>Example 3 - <span>Version_8 </span></h1>
		<p>getUserMedia() - getAudioTracks() - AudioContext() - createMediaStreamSource() - <a href="https://github.com/higuma/mp3-lame-encoder-js">Mp3LameEncoder()</a></p>
		<button class="btn waves-effect waves-light" onclick="start()" id="startBtn">Start</button>
		<button class="btn waves-effect waves-light" id="stopBtn">Stop</button>
		<br>		
		<audio controls></audio>
		<br>
		<a id="download" class="hide">Download Audio</a>
    <br>
		<button class="btn waves-effect waves-light" onclick="showCode()">Show Code</button>
	</div>
	<hr>
	<pre style="font-family: GillSans, Calibri, Trebuchet, sans-serif;" class="hide"></pre>

	<script src="./Mp3LameEncoder.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
	<script class="scriptCode">
		let startBtn = document.getElementById('startBtn');
		let stop_Btn = document.getElementById('stopBtn');
		let pre = document.querySelector('pre');
		let downloadLink = document.getElementById('download');
		let arrayAudio = [];
		let audioElement = document.querySelector('audio');
		let encoder = null;

		function start() {
			navigator.mediaDevices.getUserMedia({ audio: true, video: false })																									/** ask permission of the user for use microphone or camera  */
			.then(gotStreamMethod2)
			.catch(logError);
		}

		function getBuffers(event) {
			var buffers = [];
			for (var ch = 0; ch < 2; ++ch)
				buffers[ch] = event.inputBuffer.getChannelData(ch);
			return buffers;
		}

		function gotStreamMethod2(stream) {
			window.AudioContext = window.AudioContext || window.webkitAudioContext;																							/** detecte the correct AudioContext for the browser */

			config = {
					bufferLen: 4096,
					numChannels: 2,
					mimeType: 'audio/mpeg'
			};

			let audioContext = new AudioContext();
			let microphone = audioContext.createMediaStreamSource(stream);																											/** Create a MediaStreamAudioSourceNode for the microphone */
			let track = stream.getTracks()[0];
			processor = (audioContext.createScriptProcessor || audioContext.createJavaScriptNode)																/** Create a ScriptProcessorNode with a bufferSize of 4096 and two input and output channel */
										.call(audioContext, config.bufferLen, config.numChannels, config.numChannels);
			encoder = new Mp3LameEncoder(audioContext.sampleRate, 160);

			processor.onaudioprocess = function(event) {																																				/** Give the node a function to process audio events */
				console.log('onaudioprocess');
				console.log(event);
				encoder.encode(getBuffers(event));
			};

			microphone.connect(processor);																																											/** connect the AudioBufferSourceNode to the gainNode */
			processor.connect(audioContext.destination);

			stop_Btn.addEventListener('click', function(){
				console.log('encoder.finish()');
				track.stop();
				microphone.disconnect();
				processor.disconnect();
				audioElement.src = URL.createObjectURL(encoder.finish());
			});
		}

		function logError(error) {
			alert(error);
			console.log(error);
		}

    function showCode() {
      pre.classList.toggle('hide');
		}

		pre.innerHTML = document.querySelector('.scriptCode').innerHTML;
	</script>
</body>
</html>
